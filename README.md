# ai-tools-timeline
A timeline of the latest AI tools!üî•

This repository encompasses the most up-to-date and comprehensive AI tools across various domains.üî•  
As I fervently track the latest trends and breakthroughs, I ensure that this repository is continuously updated with fresh insights and cutting-edge developments in AI research. It serves as a curated collection for anyone keen on exploring AI tools.üé®‚ú®  
Feel free to fork this repository, submit pull requests, or open issues to discuss. üöÄ

* [LLM](#llm)
* [Image Generation](#image_generation)
* [Image Tool](#image_tool)
* [Video Generation](#video_generation)
* [Video Tool](#video_tool)
* [3D](#3d)
* [Font](#font)


## <span id="llm">LLM</span>

| Date     | Release [Samples]                                                                 | Description                                                                                                                   | Author[Organization]                      | Open Source | Ability              |
| -------- | --------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------- | ----------- | -------------------- |
| 23.11.20 | [Video-LLaVA](https://github.com/PKU-YuanGroup/Video-LLaVA)                       | Learning United Visual Representation by Alignment Before Projection.                                                         | Peking University et al                   | ‚úÖ          | `LLM`                | 
| 23.12.06 | [Gemini](https://deepmind.google/technologies/gemini)                             | Gemini is built from the ground up for multimodality ‚Äî reasoning seamlessly across text, images, video, audio, and code.      | Google                                    | ‚ùå          | `LLM`                | 
| 24.01.27 | [MoE-LLaVA](https://github.com/PKU-YuanGroup/MoE-LLaVA)                           | Mixture of Experts for Large Vision-Language Models.                                                                          | Peking University et al                   | ‚úÖ          | `LLM`                | 
| 24.02.14 | [Large World Model (LWM)](https://largeworldmodel.github.io/)                     | World Model on Million-Length Video and Language with RingAttention.                                                          | UC berkeley                               | ‚úÖ          | `LLM`                | 
| 24.02.21 | [Gemma](https://github.com/google/gemma_pytorch)                                  | Gemma is a family of lightweight, state-of-the art open models built from research and technology used to create Google Gemini models.| Google                            | ‚úÖ          | `LLM`                | 
| 24.02.21 | [gemma.cpp](https://github.com/google/gemma.cpp)                                  | lightweight, standalone C++ inference engine for Google's Gemma models.                                                       | Google                                    | ‚úÖ          | `LLM`                | 


## <span id="image_generation">Image Generation</span>

| Date     | Release [Samples]                                                                 | Description                                                                                                                   | Author[Organization]                      | Open Source | Ability              |
| -------- | --------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------- | ----------- | -------------------- |
| 23       | [Vispunk Visions](https://vispunk.com/image)                                      | Text-to-Image generation platform.                                                                                            | -                                         | ‚ùå          | `Text-to-Image`      | 
| 24.01.22 | [RPG-DiffusionMaster](https://github.com/YangLing0818/RPG-DiffusionMaster)        | AMastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs.                              | Peking University et al                   | ‚úÖ          | `Text-to-Image`      | 


## <span id="image_tool">Image Tool</span>

| Date     | Release [Samples]                                                                 | Description                                                                                                                   | Author[Organization]                      | Open Source | Ability              |
| -------- | --------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------- | ----------- | -------------------- |
| 24.02    | [BRIA-RMBG-1.4](https://huggingface.co/spaces/briaai/BRIA-RMBG-1.4)               | An open-source model for background removal.                                                                                  | BRIA.AI                                   | ‚úÖ          | `Background-removal` | 


## <span id="video_generation">Video Generation</span>

| Date     | Release [Samples]                                                                 | Description                                                                                                                   | Author[Organization]                      | Open Source | Ability              |
| -------- | --------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------- | ----------- | -------------------- |
| 23       | [VideoComposer](https://videocomposer.github.io/)                                 | Compositional Video Synthesis with Motion Controllability.                                                                    | Alibaba                                   | ‚úÖ          | `Text/Image-to-Video`| 
| 23       | [Neural Frames](https://www.neuralframes.com/)                                    | Discover the synthesizer for the visual world.                                                                                | -                                         | ‚ùå          | `Text-to-Video`      | 
| 23       | [Align your Latents](https://research.nvidia.com/labs/toronto-ai/VideoLDM/)       | High-Resolution Video Synthesis with Latent Diffusion Models.                                                                 | NVIDIA                                    | ‚ùå          | `Text-to-Video`      | 
| 23.05.12 | [Stable Animation](https://stability.ai/news/stable-animation-sdk)                | A powerful text-to-animation tool for developers.                                                                             | Stability AI                              | ‚ùå          | `Text/Image-to-Video`| 
| 23.07    | [AnimateDiff](https://github.com/guoyww/animatediff/)                             | Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning.                                             | Yuwei Guo et al                           | ‚úÖ          | `Text/Image-to-Video`| 
| 23       | [FullJourney](https://www.fulljourney.ai/)                                        | Your complete suite of AI Creation tools at your fingertips.                                                                  | -                                         | ‚ùå          | `Text-to-Video`      | 
| 23       | [Zeroscope](https://huggingface.co/spaces/fffiloni/zeroscope)                     | Zeroscope Text-to-Video.                                                                                                      | -                                         | ‚úÖ          | `Text-to-Video`      | 
| 23       | [Magic Hour](https://magichour.ai/)                                               | AI Video for Creators made simple.                                                                                            | -                                         | ‚ùå          | `Text/Image-to-Video`| 
| 23.09.04 | [VideoGen](https://videogen.github.io/VideoGen/)                                  | A Reference-Guided Latent Diffusion Approach for High Definition Text-to-Video Generation.                                    | Baidu                                     | ‚ùå          | `Text-to-Video`      | 
| 23       | [Vispunk Motion](https://vispunk.com/video)                                       | Create realistic videos using just text.                                                                                      | -                                         | ‚ùå          | `Text-to-Video`      | 
| 23       | [Moonvalley](https://moonvalley.ai/)                                              | Moonvalley is a groundbreaking new text-to-video generative AI model.                                                         | Moonvalley.ai                             | ‚ùå          | `Text-to-Video`      | 
| 23       | [Deforum](https://deforum.art/)                                                   | Deforum leverages Stable Diffusion to generate evolving AI visuals.                                                           | -                                         | ‚úÖ          | `Text/Image-to-Video`| 
| 23       | [Genmo](https://www.genmo.ai/create/video)                                        | Magically make videos with AI.                                                                                                | -                                         | ‚ùå          | `Text/Image-to-Video`| 
| 23       | [Gen-2](https://research.runwayml.com/gen2)                                       | A multi-modal AI system that can generate novel videos with text, images, or video clips.                                     | Runway                                    | ‚ùå          | `Text/Image-to-Video`| 
| 23       | [Morph Studio](https://www.morphstudio.com/)                                      | With our Text-to-Video AI Magic, manifest your creativity through your prompt.                                                | -                                         | ‚ùå          | `Text-to-Video`      | 
| 23       | [Decohere](https://www.decohere.ai/)                                              | Create what can't be filmed.                                                                                                  | -                                         | ‚ùå          | `Image-to-Video`     | 
| 23       | [Assistive](https://assistive.chat/product/video)                                 | Meet the generative video platform that brings your ideas to life.                                                            | -                                         | ‚ùå          | `Text/Image-to-Video`| 
| 23.10.04 | [Hotshot-XL](https://github.com/hotshotco/Hotshot-XL)                             | Hotshot-XL is an AI text-to-GIF model trained to work alongside Stable Diffusion XL.                                          | -                                         | ‚úÖ          | `Text-to-Video`      | 
| 23.10.12 | [Show-1](https://showlab.github.io/Show-1/)                                       | Marrying Pixel and Latent Diffusion Models for Text-to-Video Generation.                                                      | National University of Singapore          | ‚úÖ          | `Text-to-Video`      | 
| 23.10.13 | [VideoCrafter1](https://arxiv.org/abs/2310.19512)                                 | Open Diffusion Models for High-Quality Video Generation.                                                                      | Tencent AI Lab                            | ‚úÖ          | `Text/Image-to-Video`| 
| 23.11.12 | [AnimateAnything](https://animationai.github.io/AnimateAnything/)                 | Fine-Grained Open Domain Image Animation with Motion Guidance.                                                                | Alibaba                                   | ‚úÖ          | `Image-to-Video`     | 
| 23.11.16 | [Emu Video](https://emu-video.metademolab.com/)                                   | Factorizing Text-to-Video Generation by Explicit Image Conditioning.                                                          | Meta                                      | ‚ùå          | `Text-to-Video`      | 
| 23.11.18 | [Make Pixels Dance](https://makepixelsdance.github.io/)                           | High-Dynamic Video Generation.                                                                                                | ByteDance Research                        | ‚ùå          | `Image-to-Video`     | 
| 23.11.21 | [Stable Video Diffusion (SVD)](https://github.com/Stability-AI/generative-models) | Stable Video Diffusion (SVD) Image-to-Video.                                                                                  | Stability AI                              | ‚úÖ          | `Image-to-Video`     | 
| 23.11.27 | [MagicAnimate](https://showlab.github.io/magicanimate/)                           | Temporally Consistent Human Image Animation using Diffusion Model.                                                            | Bytedance                                 | ‚úÖ          | `Image+Motion-to-Video`
| 23.11.29 | [Pika 1.0](https://www.pika.art/)                                                 | Pika Labs is revolutionizing video-making experience with AI.                                                                 | Pika                                      | ‚ùå          | `Text/Image-to-Video`| 
| 23.11.30 | [Make-Your-Video](https://doubiiu.github.io/projects/Make-Your-Video/)            | Customized Video Generation Using Textual and Structural Guidance.                                                            | Tencent AI Lab                            | ‚úÖ          | `Text-to-Video`      | 
| 23.12    | [DomoAI](https://domoai.app/)                                                     | Amplify Your Creativity with DomoAI.                                                                                          | DomoAI                                    | ‚ùå          | `Image/Video-to-Video`|
| 23.12.12 | [W.A.L.T](https://walt-video-diffusion.github.io/)                                | Photorealistic Video Generation with Diffusion Models.                                                                        | Stanford et al                            | ‚ùå          | `Text/Image-to-Video`| 
| 23.12.15 | [I2VGen-XL](https://i2vgen-xl.github.io/)                                         | High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models.                                                          | Alibaba                                   | ‚úÖ          | `Image-to-Video`     | 
| 23.12.20 | [VideoPoet](https://sites.research.google/videopoet/)                             | A large language model for zero-shot video generation.                                                                        | Google                                    | ‚ùå          | `Text/Image-to-Video`| 
| 23.12.22 | [Fairy](https://fairy-video2video.github.io/)                                     | Fast Parallelized Instruction-Guided Video-to-Video Synthesis.                                                                | Meta                                      | ‚ùå          | `Video-to-Video`     | 
| 24.01.18 | [VideoCrafter2](https://ailab-cvc.github.io/videocrafter2/)                       | Overcoming Data Limitations for High-Quality Video Diffusion Models.                                                          | Tencent AI Lab                            | ‚úÖ          | `Text/Image-to-Video`| 
| 24.02.06 | [Boximator](https://boximator.github.io/)                                         | Generating Rich and Controllable Motions for Video Synthesis.                                                                 | ByteDance Research                        | ‚ùå          | `Text-to-Video`      | 
| 24.02.06 | [DynamiCrafter](https://doubiiu.github.io/projects/DynamiCrafter/)                | Animating Open-domain Images with Video Diffusion Priors.                                                                     | The Chinese University of Hong Kong et al | ‚úÖ          | `Image-to-Video`     | 
| 24.02.16 | [Sora](https://openai.com/sora)                                                   | Creating video from text.                                                                                                     | OpenAI                                    | ‚ùå          | `Text-to-Video`      | 


## <span id="video_tool">Video Tool</span>

| Date     | Release [Samples]                                                                 | Description                                                                                                                   | Author[Organization]                      | Open Source | Ability              |
| -------- | --------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------- | ----------- | -------------------- |
| 24.02.07 | [Anything in Any Scene](https://anythinginanyscene.github.io/)                    | Photorealistic Video Object Insertion.                                                                                        | XPeng Motors                              | ‚úÖ          | `Video-edit`         |
| 24.02.16 | [V-JEPA](https://github.com/facebookresearch/jepa)                                | Video Joint Embedding Predictive Architecture.                                                                                | Meta AI Research                          | ‚úÖ          | `Video-predict`      |


## <span id="3d">3D</span>

| Date     | Release [Samples]                                                                 | Description                                                                                                                   | Author[Organization]                      | Open Source | Ability                    |
| -------- | --------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------- | ----------- | -------------------------- |
| 23       | [Meshy](https://www.meshy.ai/)                                                    | Create Stunning 3D Game Assets with AI.                                                                                       | Meshy                                     | ‚ùå          | `Text-to-3D`„ÄÅ`Image-to-3D` |


## <span id="font">Font</span>

| Date     | Release [Samples]                                                                 | Description                                                                                                                   | Author[Organization]                      | Open Source | Ability                    |
| -------- | --------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------- | ----------- | -------------------------- |
| 21.03.29 | [DG-Font](https://github.com/ecnuycxie/DG-Font)                                   | Deformable Generative Networks for Unsupervised Font Generation.                                                              | Yangchen Xie et al                        | ‚úÖ          | `Font-Generation`          |
| 23.03.20 | [CF-Font](https://github.com/wangchi95/CF-Font)                                   | Content Fusion for Few-shot Font Generation.                                                                                  | Chi Wang et al                            | ‚úÖ          | `Font-Generation`          |


